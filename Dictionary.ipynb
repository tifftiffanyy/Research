{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /opt/anaconda3/lib/python3.7/site-packages (0.42.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /opt/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (4.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with csv file\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword(path):\n",
    "    stopwords = []\n",
    "    with open(path, 'r', encoding='UTF-8') as file:\n",
    "        for data in file.readlines():\n",
    "            data = data.strip()\n",
    "            stopwords.append(data)\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_my_csv(path):\n",
    "    folder = pd.read_csv(path, header=0,encoding='utf-8',dtype=str)\n",
    "    folder = folder.head(800)\n",
    "    folder = folder.loc[:,\"fulltext\"]\n",
    "    folder = folder.tolist()\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenization(csv_path, stop_path):\n",
    "    folder = read_my_csv(csv_path)\n",
    "    stopwords = stopword(stop_path)\n",
    "    tokens = []\n",
    "    for sentence in folder:\n",
    "        result = []\n",
    "        seg_list = jieba.cut(sentence, cut_all = False)\n",
    "        for word in seg_list:\n",
    "            if word not in stopwords:\n",
    "                result.append(word)\n",
    "        tokens.append(result)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diction_csv(csv_path, stop_path):\n",
    "    folder = read_my_csv(csv_path)\n",
    "    stopwords = stopword(stop_path)\n",
    "    mydiction = {}\n",
    "    for sentence in folder:\n",
    "        seg_list = jieba.cut(sentence, cut_all = False)\n",
    "        for words in seg_list:\n",
    "            if words not in stopwords:\n",
    "                if words in mydiction:\n",
    "                    mydiction[words] += 1\n",
    "                else:\n",
    "                    mydiction[words] = 1\n",
    "    mydictionary = sorted(mydiction.items() , reverse=True, key=lambda x: x[1])\n",
    "    return mydictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_try(csv_path, stop_path):\n",
    "    tokens = tokenization(csv_path, stop_path)\n",
    "    model = gensim.models.Word2Vec(size=150, window=10, min_count=2, workers=10, iter=10)\n",
    "    model.build_vocab(tokens)\n",
    "    model.train(tokens, total_examples=model.corpus_count, epochs=30)\n",
    "    synonym = model.wv.most_similar(positive=\"吸引\", topn = 10)\n",
    "    similarity = model.wv.similarity(\"吸引\", \"庞大\")\n",
    "    return synonym, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/mf/8p_wygc566v34zgt9268g6780000gn/T/jieba.cache\n",
      "Loading model cost 0.653 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('技术', 0.595899224281311), ('创新', 0.5219643115997314), ('吸引力', 0.5177100896835327), ('战略性', 0.517513632774353), ('具备', 0.5112055540084839), ('公司', 0.5109722018241882), ('上市', 0.5070338249206543), ('精神', 0.5065947771072388), ('守住', 0.5053523182868958), ('收获', 0.5050301551818848)], 0.26144058)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #print(diction_csv(\"/Users/tiff/Desktop/Research/Tiffany.csv\", \"/Users/tiff/Desktop/Research/stopword.txt\"))\n",
    "    #print(read_my_csv(\"/Users/tiff/Desktop/Research/Tiffany.csv\"))\n",
    "    #print(stopword(\"/Users/tiff/Desktop/Research/stopword.txt\"))\n",
    "    #print(tokenization(\"/Users/tiff/Desktop/Research/Tiffany.csv\", \"/Users/tiff/Desktop/Research/stopword.txt\"))\n",
    "    print(model_try(\"/Users/tiff/Desktop/Research/Tiffany.csv\", \"/Users/tiff/Desktop/Research/stopword.txt\"))\n",
    "    #model_try(tokens)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
